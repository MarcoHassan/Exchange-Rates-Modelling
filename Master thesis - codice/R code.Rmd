---
title: "Master thesis code - FX rates. A nonlinear evaluation"
output: html_notebook
---

Libraries used
```{r}
library("Quandl") ##Offers to connect to download various eco and financial datasets avaialable on quandl.com through the Quandl API. !!At the moment not used!!
library("quantmod") ##same principle as Quandl, not limited by the amount of API calls though and connect to multiple daset providers. In this study we will mainly query the FRED database.
library(forecast) ## for detrending the times series
```

Specify quandl API
```{r}
Quandl.api_key("enter api key")
```


===============
Data Collection
===============

STILL HAVE TO DOWNLOAD FORWARD RATES TO DO OUT OF SAMPLE PERFORMANCE CHECK

Specify function to get symbols
```{r}
get_Symbols <- function(x){
                           lapply(x, function(sym){getSymbols(sym, src = "FRED",
                                                              return.class = "xts",
                                                              auto.assign = F)})
  ## auto.assign specifies that not the ticker should be passed
}
```

###########
FX - rates
###########

Download foreign exchange rates
```{r}
Symbols <- c("EXUSUK", "EXJPUS", "EXSZUS")

FX <-  get_Symbols(Symbols)

## Invert the USUK rate to UKUS to keep it consistent with the other series
FX[[1]] <- 1/FX[[1]]

FX <- do.call(merge, FX)

colnames(FX)[c(1,3)] <- c("EX_UKUS", "EX_JPUS","EX_CHUS")

## notice like that all of the evaluation will be performed compared to the usa. if you want to make smaller bilateral comparison you need to download the other forex.
```

###
GDP
###

GDP is an aggregated statistic that is published on a quarterly basis. You can use monthly proxies. Electricity consumption? Industrial production? <-> this is normalized to 100. Is that good?
```{r}
## use industrial production? 
## use unemployment rate. This approach preferred
Symbols <- c("LRUN64TTUSM156N", "LRUN64TTJPM156N", "LMUNRRTTCHM156N", "LMUNRRTTGBM156N") #F not seasonally adjusted.

UNply <- get_Symbols(Symbols)

UNply <- do.call(merge, UNply) ## notice the unemployment series for UK starts just in the 90s.

colnames(UNply) <- c("UN_US", "UN_JP", "UN_CH", "UN_UK")
```


################
Short term bills
################

Treasury bills for capturing short term attractiveness of investments
```{r}
Symbols <- c("TB3MS","INTGSTJPM193N","TBDRUKM")
 ## 3 months bill rate usa; secondary market.
 ## bill for japan; explaination not clear. check at it again to clearly understand what it is precisely.
 ## treasury bill for uk

bills <- get_Symbols(Symbols)

bills<- do.call(merge, bills) 

colnames(bills) <- c("TB_US", "TB_JP", "TB_CH") ## Treasury bills

## above not available for switzerland. use interbank rate for it.
```


#############
Monetary base
#############

Problem you are taking differentials for all of the above measures. The values should consequently be consistent and comparable. Use M3 for all.
```{r}
Symbols <- c("MYAGM3USM052N", "MYAGM3JPM189N", "MABMM301GBM189N", "MABMM301CHM189N") #us, jp, uk, not seasonally adjusted. 

M3 <- get_Symbols(Symbols)

M3 <- do.call(merge, M3)

colnames(M3) <- c("M3_US", "M3_JP", "M3_UK", "M3_CH")
```

Extract M1
```{r}
Symbols <- c("M1NS", "MANMM101JPM189N", "MANMM101GBM189N", "MANMM101CHM189N") 

M1 <- get_Symbols(Symbols)

M1 <- do.call(merge, M1)

colnames(M1) <- c("M1_US", "M1_JP", "M1_UK", "M1_CH")
```

###
CPI
###

```{r}
## all not seasonally adjusted, all with basis 2015
Symbols <- c('CHECPIALLMINMEI', 'JPNCPIALLMINMEI', 'GBRCPIALLMINMEI', 'USACPIALLMINMEI')

CPI <- get_Symbols(Symbols)

CPI <- do.call(merge, CPI)

colnames(CPI) <- c("CPI_CH", "CPI_JP", "CPI_UK", "CPI_US")
  
## Important difference, lapply applies a function over a list, do.call calls a function with a list of arguments.

## CHECPIALLMINMEI ## switzerland from FRED; harmonised index; basis 2015
## JPNCPIALLMINMEI ## japan; basis 2015
## GBRCPIALLMINMEI ## uk; basis 2015
## USACPIALLMINMEI ## usa, basis 2015
```

##############
Trade balances
##############

```{r}
## Current accounts are available just on quartal level. Two options use current accounts and hold it fix for the entire quartal.

## Option two; chosen option, find a proxy for the current account balance.

Symbols <- c("XTNTVA01CHM664N", "XTNTVA01JPM664N", "XTNTVA01USM664N", "XTNTVA01GBM664N")
 ## net trade. monthly not seasonally adjusted. broad proxy for current account balance.

Trade <- get_Symbols(Symbols)

Trade <- do.call(merge, Trade)

colnames(Trade) <- c("T_CH", "T_JP", "T_US", "T_UK")

## check at the currency.
```


###########################
Merge all of the statistics
###########################

```{r}
data <- merge.xts(FX, bills, CPI, M1, M3, Trade, UNply) ##dagli anni '90 al 2005 hai tutte le statistiche.

rm(list=setdiff(ls(), "data")) ## clean the workspace just keeping the data
```

UK statistics are poor. For the other countries you can run the analysis back to the '70s. For UK because of M3 and especially unemployment rate the comparison is much more limited.


======================
Descriptive Statistics
======================

This section continues with general descriptive statistics trying to understand the behaviour of the exogenous series and trying to test whether the latter are indeed exogenous.

Step 1: Seasonality
In order to derive meaningful conclusions in the following sections it is necessary to assure that the series do not display profund autocorrelation. This would in fact inhibit the idependency of the data and would bias all of the resulting statistics.

Step 1.1: Check for underlying trend in the series. 
```{r}
Season <- function(t_series,  idx){
  trend <- ma(na.trim(t_series), order = 12, centre = T)
  Seasonality <- as.ts(na.trim(t_series)) - trend
  Seasonality <- na.contiguous(Seasonality)
  if(idx == 1) plot(Seasonality)
  if(idx == 2) acf(Seasonality)
  if(idx == 3) pacf(Seasonality)
  if(idx == 4){
    converted_ts <- ts(na.trim(t_series), frequency = 12)
    decompose_ts <- decompose(converted_ts, "additive")
    adjust_ts <- converted_ts - decompose_ts$seasonal
    plot(adjust_ts)
  }
}

helper <- c("US", "JP", "CH", "UK")
par(mfrow=c(2,2))
for (i in helper){Season(eval(parse(text = paste0("data$UN_", i))), 3)} ##significant autoregressive lags
```

Do similar for other functions and incorporate all of the code in one single function if you want to be fancy
```{r}
helper <- c("US", "JP", "CH", "UK")
par(mfrow=c(2,2))
for (i in helper){Season(eval(parse(text = paste0("data$M1_", i))), 2)} ## also for M1 and M3 profound seasonality
```

CPI
```{r}
helper <- c("US", "JP", "CH", "UK")
par(mfrow=c(2,2))
for (i in helper){Season(eval(parse(text = paste0("data$CPI_", i))), 2)} ## also for CPI profound seasonality
```

Test 
```{r}
ts_beer = ts(na.trim(data$UN_US), frequency = 12)
decompose_beer = decompose(ts_beer, "additive")
adjust_beer = ts_beer - decompose_beer$seasonal
plot(adjust_beer)

plot(decompose_beer$seasonal)
```





















Library
```{r}
library(rvest)
```

## not working for SNB table; does not manage to read the information from the table. This probably because it is a special kind of table. With normal table from of wikipedia works.
Web scraping to get tables
```{r}
url <- "https://en.wikipedia.org/wiki/Economy_of_Italy"
population <- url %>%
  read_html() %>%
  html_nodes(xpath='//*[@id="mw-content-text"]/div/table[2]') %>%
  html_table()
population <- population[[1]]

head(population)
```

