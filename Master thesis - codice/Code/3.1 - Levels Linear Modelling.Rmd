---
title: "Level Linear Modelling"
output: rmarkdown::github_document
---

Libraries used
```{r}

## String manipulation library using regualr expressions

library(stringr) ## to make use of regular expressions to parse strings

## For applying Johansen test for cointegration
library(urca)

## VAR packages

library(vars)  ## to estimate VAR lag with exogenous variables
library(tsDyn) ## to estimate the VAR model and perform the out of sample fit based on rolling window.

## Import functions from the relating project
source("~/Exchange-Rates-Modelling/Master thesis - codice/Code/0 - functions.R")
```


Specify a function to clean the environment and do it
```{r}
clean <- function() 
{
  ENV <- globalenv()
  ll <- ls(envir = ENV)
  ll <- ll[!(ll %in% c("data", "clean", "import", "write", "evalue", "acf_plots",
                       "adfTest", "seasonality", "suspectFrequency", "spa"))]
  rm(list = ll, envir = ENV)
}
```

```{r}
## Insert your path here
path <- "/Users/Marco Hassan/Exchange-Rates-Modelling/Master thesis - codice/Written\ Data/rawdata.csv"

data <- read.csv(path)

data <- as.xts(data[,-1], order.by = as.Date(data[,1]))
```

================================
Univariate times series analysis
================================

This section starts with the analysis of the cleaned dataset.

In a first step I will try to check whether the Meese-Rogoff paradox holds in the analyzed time period. I will work with the USA as the benchmark series and apply the different macroeconomics models to linearly estimate the FX_rates.

General model:

EX = const. + b1 M_USFR + b2 UN_USFR + b3 TB_USFR + b4 CPI_USFR + b5(TB_US) + b6 TB_FR

I will test the different models:

(i) Frenkel Bilson -> b4, b5, b6 = 0

(ii) Dornbusch-Frankel -> b5, b6 = 0

(iii) Hooper Morton -> no constraint


As in the case of Meese and Rogoff forecasting will be performed at one, three, six and twelwe months.

Cite Meese and Rogoff in the thesis: 
The purpose of considering multiple forecast horizons in this type of experiment is to see whether the structural models do better than time series models in the long run, when adjustment due to lags and/or a serially correlated error term has taken place. Of course, when lags and serial correlation are fully incorporated into the structural models, a consistently estimated true structural model will outpredict a time series model at all
horizons in a large sample.

===============
Random walk fit
===============

Random walk without drift prediction using rolling series
```{r}
## In the other models I will use 3/4 of the sample to train the data and the rest to predict. Be consistent to facilitate comaprison at a later stage.
three_fourth <- round(nrow(data)*(3/4))

## to create new series transform in data frame as before

data2 <- as.data.frame(data)

for(iPred in c(1,3,6,12)) 
  { 
    helper <- c("JP", "UK", "CH")
    for(jCountry in helper)
    {
    data2[, paste0("rwPred" , iPred, "_", jCountry, "US")] <- NA
    }
  } 

data2 <- as.xts(data2, order.by = index(data))## transform back to xts
data <- data2
rm(data2)
```

Fit the Random Walk prediction
```{r}
for(iPred in c(1,3,6,12)) 
  { 
    helpCountry <- c("JP", "UK", "CH")
    for(jCountry in helpCountry)
    {
        for(kRow in (three_fourth+1):nrow(data)) 
        {
         if ((iPred != 1) & (kRow+(iPred-2) == nrow(data))) break
         data[kRow+(iPred-1), paste0("rwPred" , iPred, "_", jCountry, "US")] <- 
           data[kRow-1, paste0("EX_", jCountry, "US")] 
        }
    }
  } 
```


==============================
Macroeconomic structural model
==============================

In contrast to Meese and Rogoff I decided to make use of the ARIMAX model here. This will allow the introduction of lagged exogenous variables and its implementation is favoured compared to the long lagged AR model used by Meese and Rogoff to my mind.

Specify rolling prediction
```{r}
## trasform to data-frame to add columns
data2 <- as.data.frame(data)

## create prediction columns

for(iPred in c(1,3,6,12)) 
  { 
    country <- c("JP", "UK", "CH")
    for(jCountry in country)
    {
    data2[, paste0("strPred" , iPred, "_", jCountry, "US")] <- NA
    }
  } 
```

Get exogenous variables for each of the series of interest
```{r}
## get exogenous parameters
for(country in c("CH", "UK", "JP"))
{
  assign(paste0("interest", country), 
         !str_detect(colnames(data2), paste0("^M3|^EX+\\D", country)) &
          str_detect(colnames(data2), paste0("\\D", country)) & 
         !str_detect(colnames(data2), "^rw|^str"))
}
```

==========
Arimax fit
==========

```{r}
## transform to ts object ot leverage on the window function
data2 <- as.ts(data2, frequency =12)

## in sample observations
in_sample <- three_fourth;
  
## Get in sample time frame
st <- tsp(data2)[1] + (in_sample-2); 
## tsp(data2)[1] gets the start of the time frame; the second block adds the in_sample time window
```

Working well just last observation disappeared somehow.
```{r}
for( LAG in c(1, 3, 6, 12) ) 
{
  for( country in c("JP", "UK", "CH") )
  {  
    for( iRow in 1:(nrow(data2)-in_sample) )
    {
      xshort <- window(data2, start = tsp(data2)[1]+ (iRow-1), end=st + iRow)
      xnew <- window(data2, start = st + iRow, end = (st +iRow)+(LAG-1))
    
      ## Specify the arimax that fits at best
      nd_pars<-expand.grid(ar=0:2,diff=0:1,ma=0:2)
      nd_aic<-rep(0,nrow(nd_pars))
      help <- eval(parse(text = paste0("interest",country)))
      
      for(jPar in seq(along=nd_aic))
      {
        nd_aic[jPar]<-AIC(arimax(xshort[,paste0("EX_", country, "US")],
                              unlist(nd_pars[jPar,1:3]), 
                              xreg = xshort[, help],
                              method = 'ML'))
      }
    
      ## save the best fit
      order <- nd_pars[which.min(nd_aic),]
      
    
      fit1 <- arimax(xshort[, paste0("EX_", country, "US")], order = unlist(order), 
                     xreg = xshort[, help], method = 'ML',  optim.method = "BFGS")
      
      ## Create an exogenous vector and specify the structur in the case of lag == 1
      ## to keep the column structure in a consistent way to fit the model
      if ( LAG == 1) new_exogenous <- t(xnew[, help])
      else new_exogenous <- xnew[, help]
      
      fcast1 <- predict(fit1, n.ahead = LAG, newxreg = new_exogenous)
      if(index(tail(xshort,1)) == nrow(data2)-LAG) break 
      ## so that you have always 12 out of sample
      data2[in_sample+(LAG-1)+iRow, 
            paste0("strPred", LAG, "_", country, "US")] <- fcast1$pred[1]
    }
  }
}
```


===============================
Vector Autoregressive Modelling
===============================

```{r}
data2 <- as.data.frame(data2)
endogenous <- c("EX_UKUS", "EX_JPUS", "EX_CHUS")
exogenous <- !str_detect(colnames(data2), "^M1|^rw|^EX|^str")

data_exogenous <-  data2[1:three_fourth, exogenous]

VARselect(data2[1:three_fourth, endogenous], lag.max = 7,
          type = "none", exogen = data_exogenous) 
## one lag the best

model <- lineVar(data2[1:three_fourth, endogenous], 1, 
                 lag = 2,
                 include = "none", 
                 model = "VAR", I = "level",
                 estim = "ML", LRinclude = "none", 
                 exogen = data_exogenous)

```

Create columns for inserting prediction results
```{r}
for(iPred in c(1,3,6,12)) 
  { 
    helper <- c("JP", "UK", "CH")
    for(jCountry in helper)
    {
    data2[, paste0("varPred" , iPred, "_", jCountry, "US")] <- NA
    }
  } 
```


Rolling prediction using VAR
```{r}
# number rolling prediction per forecasting time frame
for(i in c(1,3,6,12))
  {
  assign(paste0("numprediction", i), sum(!is.na(data2[, paste0("rwPred", i, "_JPUS")])))
  }

## Estimate the rolling window forecast
for(j in c("UK", "JP", "CH")) 
  {
    for(i in c(1,3,6,12))
    {
    parsed_text1 <- evalue(paste0("numprediction", i))
    assign(paste0("endRow",i), nrow(data2) +1 - parsed_text1)
    assign(paste0("pred_model", i), 
           predict_rolling(model, nroll = parsed_text1, n.ahead = i))
    parsed_text2 <- evalue(paste0("pred_model", i))
    parsed_text3 <- evalue(paste0("endRow", i))
    if(j == "UK") list_member = 1
    if(j == "JP") list_member = 2
    if(j == "CH") list_member = 3
    data2[parsed_text3:nrow(data2), 
         paste0("varPred", i, "_", j, "US")] <- parsed_text2$pred[list_member]
    }
}
```

Convert back to xts
```{r}
data2 <- as.xts(data2, order.by = index(data))## transform back to xts
data <- data2

clean()
```


Write the data
```{r}
write(data, "level_linear_pred.csv")
```

============================================
Estimation via Vector Error Correction Model 
============================================

Notice here you are running a different model compared to the VAR above. Above you tested a model where the endougenous variables were the exogenous exchange rates were assumed to be possibly endougenous and the maacroeconomic variables were assumed to be exogenous. 

Now the model is DIFFERENT as you are actually testing whether the structural macroeconomic variables are endogenouusly correlated witht eh exchange rates of interest and testing for forecasting superior predictive ability given the stable relation between two of the variables.

Create columns for inserting prediction results
```{r}
## trasform to data-frame to add columns
data2 <- as.data.frame(data)

for(iPred in c(1,3,6,12)) 
  { 
    helper <- c("JP", "UK", "CH")
    for(jCountry in helper)
    {
    data2[, paste0("vecmPred" , iPred, "_", jCountry, "US")] <- NA
    }
  } 
```

Create a data frame containing the cointegrated series for the japan series
```{r}
## Specify in Sample dataset
three_fourth <- round(nrow(data)*(3/4))
```

Rolling prediction using VECM - make use of the same rolling_prediction function
```{r}
# number rolling prediction per forecasting time frame
for(i in c(1,3,6,12))
{
  assign(paste0("numprediction", i), sum(!is.na(data2[, paste0("rwPred", i, "_JPUS")])))
}

## Estimate the rolling window forecast
for( jCountry in c("CH", "JP", "UK") )
{
  sample <- cbind(
           data2[1:three_fourth,paste0("EX_", jCountry, "US")], 
           data2[1:three_fourth,paste0("M3_", "US", jCountry)], 
           data2[1:three_fourth,paste0("TB_", "US", jCountry)],
           data2[1:three_fourth,paste0("UN_", "US", jCountry)], 
           data2[1:three_fourth,paste0("CPI_", "US", jCountry)],
           data2[1:three_fourth,paste0("T_", "US", jCountry)])
  
  ## Create a data frame containing the cointegrated series for the japan series
  assign(paste0("data_", jCountry),  sample)
  
  ## Select Lag length and specify model
  LAG <- min(VARselect(evalue(paste0("data_", jCountry)), 
                       lag.max = 7, type = "none")$selection
  ) 
  
  model <- tsDyn::VECM(evalue(paste0("data_", jCountry)), 
                       lag = LAG, estim = "ML", LRinclude = 'none'
  )
  
  for(i in c(1,3,6,12))
  {
    parsed_text1 <- evalue(paste0("numprediction", i))
    assign(paste0("endRow",i), nrow(data2) +1 - parsed_text1)
    assign(paste0("pred_model", i), 
           predict_rolling(model, nroll = parsed_text1, n.ahead = i))
    parsed_text2 <- evalue(paste0("pred_model", i))
    parsed_text3 <- evalue(paste0("endRow", i))
    data2[parsed_text3:nrow(data2), 
          paste0("vecmPred", i, "_", jCountry, "US")] <- parsed_text2$pred[1]
  }
}
```


Convert back to xts
```{r}
data2 <- as.xts(data2, order.by = index(data))## transform back to xts
data <- data2

clean()
```

Write the data
```{r}
write(data, "level_linear_pred.csv")
```

