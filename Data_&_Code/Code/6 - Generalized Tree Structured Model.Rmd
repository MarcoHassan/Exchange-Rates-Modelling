---
title: "R Notebook"
output: rmarkdown::github_document
---

Step 0:

Fix the partition space according to the a-th quantile. 

Step 1:

Compute the global model fit.

Step 2:

Partition and rerun the model over all the possible different partitions. Check at improvements in the likelihood  measure.

Step 3:

Iterate.

Notice the importance of getting threshold values endogenously in comparison with the general TAR estiation procedure of Tsay or Hansen.


Useful Libraries
```{r}
## String manipulation library using regualr expressions

library(stringr) ## to make use of regular expressions to parse strings

## To handle times series .xts objects
library(xts)

## To estimate OLS
library(TSA)

## To make use of SQL queries
library(sqldf)

## To set up the generalized tree structured model
library(partykit)

## Import self defined functions
source("0 - functions.R")
```

Specify a function to clean the environment and do it
```{r}
clean <- function() 
{
  ENV <- globalenv()
  ll <- ls(envir = ENV)
  ll <- ll[!(ll %in% c("data", "clean", "import", "write", "evalue", "acf_plots",
                       "adfTest", "seasonality", "suspectFrequency", "spa",
                       "logLikelihood", "partitionSpace", "fork", "bestFit", "GTS",
                       "prunedTree", "GTSEstimate", "createTree", "AICcSmall"))]
  rm(list = ll, envir = ENV)
}
```

===========
Data Import
===========

```{r}
## Insert your path here
path <- "/Users/Marco Hassan/Exchange-Rates-Modelling/Master thesis - codice/Written Data/linear_pred.csv"

data <- read.csv(path)

data <- as.xts(data[,-1], order.by = as.Date(data[,1]))
```

==========================
Tree Structured Estimation
==========================

Create the partitioned space of exogenous regressors. 

From Audrino Paper: Typically, we fix the empirical quantiles as a = i/mesh, i =
1,...,mesh - 1, where mesh determines the fineness of the grid on which we search for multivariate thresholds. Typically, we choose mesh = 8 (I chose 4, my choice is first and foremost motivated by the fact that the small sample size does not allow to have to small partitions for obvious estimation issues.)


Get exogenous variables for each of the series of interest
```{r}
## get exogenous parameters
for(country in c("CH", "UK", "JP"))
{
  assign(paste0("interest", country), 
          str_detect(colnames(data), paste0("\\D", country)) & 
         !str_detect(colnames(data), "^rw|^str|^var|^vecm|^M1")) ## With M3
}
```

Start to implement the model for CH-US
```{r}
exogen <- data[,interestUK]
exogen$Time <- c(1:nrow(exogen))
exogen <- exogen[,c(6,1,3,2,4,5)]

three_fourth <- round(3/4 * nrow(exogen))
insample <- exogen[1:three_fourth,]
```

==========================
Estimate the general model
==========================

Use OLS as the benchmark model. 

## Algorithm

```
(i) For each partition break just keep the highest likelihood function and save the structure of the partition. 

(ii) Iterate until you reach the highest number of partitions that has to be prespecified by the user.

(iii) Prune using Information criteria. 
```

Run the GTS
```{r}
## Calculate computation time
# a <- system.time(GTS(insample, max_Partition = 5))

# a[3] * 48 (out of sample observations) -> takes around 13 min. to run recompute the model at each step.

```

Create Tree
```{r}
## Define break structure and models.
suppressMessages( GTS(insample, max_Partition = 5) )

newdata <- cbind(1, exogen[175,-ncol(exogen)])

if(is.null(max_lik2))
{
  if(newdata[, max_lik1$optVar] > max_lik1$optBreak)
  {newdata %*% max_lik1$right_model} else{
    newdata %*%  max_lik1$left_model
  }

} else{
  ## Save structure and results in a formatted way.
  createTree(iterate = max_Partition, plot = T) ## to plot without pruning
  
  ## Pruning via AICc
  ##best_Partition <- prunedTree()
  ##createTree(iterate = best_Partition)
  
  ## Out of Sample Forecast
  GTSEstimate(newdata)
}

```


## fai il plot degli split points sulle variabli
(idea pag 14)[https://cran.r-project.org/web/packages/party/vignettes/party.pdf] 


==================
Rolling Estimation
==================

Add GTS prediction
```{r}
## trasform to data-frame to add columns
data2 <- as.data.frame(data)
## create prediction columns
for(iPred in c(1,3,6,12)) 
  { 
    country <- c("JP", "UK", "CH")
    for(jCountry in country)
    {
    data2[, paste0("GTSPred" , iPred, "_", jCountry, "US")] <- NA
    }
  } 
```

Get exogenous variables for each of the series of interest
```{r}
## get exogenous parameters
for(country in c("CH", "UK", "JP"))
{
  assign(paste0("interest", country), 
          str_detect(colnames(data2), paste0("\\D", country)) & 
         !str_detect(colnames(data2), "^rw|^str|^var|^vecm|^GTS|^M1|^OLS")) ## With M3
}
```

```{r}
## in sample observations
three_fourth <- round(3/4 * nrow(data))
st <- three_fourth;
```


Rolling Prediction OLS
```{r}
for( LAG in c(3, 6, 12) ) 
{
  for( country in c("UK", "CH", "JP") )
  {  
    data3 <- data2[, get(paste0("interest", country))]
    data3 <- as.xts(data3, order.by = as.Date(index(data3)))
    
    iteration = 0
    
    #Close File Connession and redirection
    if(sink.number() > 0)
    { 
      sink(NULL, type="output")
      close(fileout)
    }
    
    ## Open File where to redirect messages of the GTS fit. This will subsequently be used to generate descriptive statistics about the average numbers of splits, variables of splits. In which partitions? Etc.
  
    fileout <- file(paste0("GTS_", country ,"_", LAG, ".txt"), open = "wt")
  
    sink(file = fileout, append = T, type = "output")
    
    for( iRow in 1:(nrow(data2)-st) )
    {
      iteration = iteration + 1
      
      beg <- 1 + (iRow-1)
      end <- st + (iRow -1)
      xshort <- data3[beg:end, ]
      
      ## Out of Sample Forecast
      beg <-  st + iRow
      end <- (st +iRow)+(LAG-1)
      xnew <- data3[beg:end, ]
      message(xnew[LAG, ncol(xnew)])
      xnew <- cbind(1, xnew[, -ncol(xnew)])
    
      GTS(xshort, max_Partition = 5)

      if(is.null(max_lik2))
      {
        if(xnew[, match(max_lik1$optVar, names(xshort))+1] > max_lik1$optBreak) 
        {fcast1 <- xnew[LAG,] %*% max_lik1$right_model} else{
          fcast1 <- xnew[LAG,] %*%  max_lik1$left_model
        }
      
      } else{
        ## Pruning via AICc
        best_Partition <- prunedTree()
        condition <- createTree(iterate = best_Partition)
        
        ## Out of sample
        fcast1 <- GTSEstimate(xnew[LAG,])
      }
      
      ## Save the forecast
      data2[st+(LAG-1)+iRow, 
            paste0("GTSPred", LAG, "_", country, "US")] <- fcast1
      
      message(iteration)
      message(fcast1)
      if(index(tail(xshort,1)) == nrow(data2)-LAG) break 
    }
  }
}
```


Write Data to csv
```{r}
write(data2, "stationary_GTS_pred.csv")
```



